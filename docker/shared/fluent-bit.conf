[SERVICE]
    Flush         1
    Log_Level     info
    Daemon        off
    Parsers_File  parsers.conf
    HTTP_Server   On
    HTTP_Listen   0.0.0.0
    HTTP_Port     2020
    storage.path  /tmp/fluent-bit/
    storage.sync  normal
    storage.checksum off
    storage.backlog.mem_limit 5M

# Input: Docker container logs
[INPUT]
    Name              forward
    Listen            0.0.0.0
    Port              24224
    Buffer_Max_Size   1M
    Buffer_Chunk_Size 64k

# Input: Application logs from mounted volume
[INPUT]
    Name              tail
    Path              /var/log/app/*.log
    Path_Key          filename
    Parser            json_app_logs
    Tag               app.*
    Refresh_Interval  5
    Read_from_Head    true
    Skip_Long_Lines   On
    Skip_Empty_Lines  On

# Input: Boss AI logs
[INPUT]
    Name              tail
    Path              /var/log/boss/*.log
    Path_Key          filename
    Parser            json_app_logs
    Tag               boss.*
    Refresh_Interval  5
    Read_from_Head    true

# Input: Subordinate AI logs
[INPUT]
    Name              tail
    Path              /var/log/subordinate/*.log
    Path_Key          filename
    Parser            json_app_logs
    Tag               subordinate.*
    Refresh_Interval  5
    Read_from_Head    true

# Input: Dashboard logs
[INPUT]
    Name              tail
    Path              /var/log/dashboard/*.log
    Path_Key          filename
    Parser            json_app_logs
    Tag               dashboard.*
    Refresh_Interval  5
    Read_from_Head    true

# Input: System logs
[INPUT]
    Name              tail
    Path              /var/log/system/*.log
    Path_Key          filename
    Parser            multiline_logs
    Tag               system.*
    Refresh_Interval  10
    Multiline         On
    Multiline_Flush   5
    Parser_Firstline  multiline_start

# Filter: Add hostname and service information
[FILTER]
    Name                record_modifier
    Match               *
    Record              hostname ${HOSTNAME}
    Record              service_type ${SERVICE_TYPE}
    Record              environment ${NODE_ENV}

# Filter: Add timestamp if missing
[FILTER]
    Name                lua
    Match               *
    Script              add_timestamp.lua
    Call                add_timestamp

# Filter: Parse and enrich boss logs
[FILTER]
    Name                grep
    Match               boss.*
    Regex               level (DEBUG|INFO|WARN|ERROR)

# Filter: Parse and enrich subordinate logs
[FILTER]
    Name                grep
    Match               subordinate.*
    Regex               level (DEBUG|INFO|WARN|ERROR)

# Filter: Add geolocation info (if available)
[FILTER]
    Name                geoip2
    Match               *
    Database            /fluent-bit/etc/GeoLite2-City.mmdb
    Lookup_key          client_ip
    Record              city        %{city.names.en}
    Record              country     %{country.names.en}

# Output: Send to Elasticsearch
[OUTPUT]
    Name                es
    Match               *
    Host                elasticsearch
    Port                9200
    Index               claude-logs
    Type                _doc
    Logstash_Format     On
    Logstash_Prefix     claude
    Logstash_DateFormat %Y.%m.%d
    Include_Tag_Key     On
    Tag_Key             @tag
    Time_Key            @timestamp
    Time_Key_Format     %Y-%m-%dT%H:%M:%S.%L%z
    Generate_ID         On
    Replace_Dots        On
    Retry_Limit         5
    Buffer_Size         false
    Suppress_Type_Name  On

# Output: Debug output (optional, disable in production)
[OUTPUT]
    Name                stdout
    Match               system.*
    Format              json_lines